#!/usr/bin/env python3
"""
Prompt Utils - æç¤ºè¯æå–å’Œåˆ†ç±»å·¥å…·

å…¬ç”¨æ¨¡å—ï¼Œæä¾›ï¼š
- AI æç¤ºè¯æå–
- æç¤ºè¯åˆ†ç±»
- æ­£åˆ™è¡¨è¾¾å¼å¿«é€Ÿæå–

ä½¿ç”¨æ–¹æ³•:
    from prompt_utils import extract_prompt, classify_prompt

    # æå–æç¤ºè¯
    result = extract_prompt(text, model="openai")

    # åˆ†ç±»æç¤ºè¯
    classification = classify_prompt(prompt, model="openai")
"""

import re
import os
import requests
from pathlib import Path

# åŠ è½½ç¯å¢ƒå˜é‡
try:
    from dotenv import load_dotenv
    root_dir = Path(__file__).parent.parent
    env_local = root_dir / ".env.local"
    env_file = root_dir / ".env"

    if env_local.exists():
        load_dotenv(env_local)
    elif env_file.exists():
        load_dotenv(env_file)
except ImportError:
    pass


# ========== é…ç½® ==========

# Pollinations API é…ç½®
POLLINATIONS_API_URL = "https://text.pollinations.ai/"
DEFAULT_MODEL = "openai"

# Gitee AI API é…ç½® (fallback 1)
GITEE_AI_API_URL = "https://ai.gitee.com/v1/chat/completions"
GITEE_AI_MODEL = "DeepSeek-V3"
GITEE_AI_API_KEY = os.environ.get("GITEE_AI_API_KEY", "")

# NVIDIA API é…ç½® (fallback 2)
NVIDIA_API_URL = "https://integrate.api.nvidia.com/v1/chat/completions"
NVIDIA_MODEL = "deepseek-ai/deepseek-v3.2"
NVIDIA_API_KEY = os.environ.get("NVIDIA_API_KEY", "mHMcKtSCRsFEXQ2gyipZS6bn1aU01szMrkCRORruRFvtbCCwmjqeO")


# ========== AI è°ƒç”¨ ==========

def call_ai(messages: list, model: str = DEFAULT_MODEL) -> str:
    """
    è°ƒç”¨ AI APIï¼Œä¾æ¬¡å°è¯• Pollinations -> Gitee AI -> NVIDIA API

    Args:
        messages: OpenAI æ ¼å¼çš„æ¶ˆæ¯åˆ—è¡¨
        model: Pollinations ä½¿ç”¨çš„æ¨¡å‹

    Returns:
        AI å“åº”å†…å®¹
    """
    errors = []

    # é¦–å…ˆå°è¯• Pollinations AI
    try:
        result = _call_pollinations_ai(messages, model)
        return result
    except Exception as pollinations_error:
        print(f"âš ï¸ Pollinations AI å¤±è´¥: {pollinations_error}")
        errors.append(f"Pollinations ({pollinations_error})")

    # Fallback 1: Gitee AI
    if GITEE_AI_API_KEY:
        print(f"ğŸ”„ å°è¯• Gitee AI (DeepSeek-V3) ä½œä¸º fallback...")
        try:
            result = _call_gitee_ai(messages)
            print("âœ“ Gitee AI è°ƒç”¨æˆåŠŸ")
            return result
        except Exception as gitee_error:
            print(f"âœ— Gitee AI ä¹Ÿå¤±è´¥: {gitee_error}")
            errors.append(f"Gitee ({gitee_error})")
    else:
        print("âš ï¸ GITEE_AI_API_KEY æœªè®¾ç½®ï¼Œè·³è¿‡ Gitee AI")

    # Fallback 2: NVIDIA API
    if NVIDIA_API_KEY:
        print(f"ğŸ”„ å°è¯• NVIDIA API (DeepSeek-V3.2) ä½œä¸º fallback...")
        try:
            result = _call_nvidia_ai(messages)
            print("âœ“ NVIDIA API è°ƒç”¨æˆåŠŸ")
            return result
        except Exception as nvidia_error:
            print(f"âœ— NVIDIA API ä¹Ÿå¤±è´¥: {nvidia_error}")
            errors.append(f"NVIDIA ({nvidia_error})")
    else:
        print("âš ï¸ NVIDIA_API_KEY æœªè®¾ç½®ï¼Œè·³è¿‡ NVIDIA API")

    # æ‰€æœ‰æœåŠ¡éƒ½å¤±è´¥
    raise Exception(f"æ‰€æœ‰ AI æœåŠ¡éƒ½å¤±è´¥: {', '.join(errors)}")


def _call_pollinations_ai(messages: list, model: str = DEFAULT_MODEL) -> str:
    """
    è°ƒç”¨ Pollinations AI API

    Args:
        messages: OpenAI æ ¼å¼çš„æ¶ˆæ¯åˆ—è¡¨
        model: ä½¿ç”¨çš„æ¨¡å‹

    Returns:
        AI å“åº”å†…å®¹
    """
    import json as json_module

    # ç¡®ä¿ model ä¸ä¸ºç©º
    if not model or not model.strip():
        model = DEFAULT_MODEL

    headers = {
        'Content-Type': 'application/json',
    }

    payload = {
        "model": model,
        "messages": messages,
    }

    response = requests.post(POLLINATIONS_API_URL, json=payload, headers=headers, timeout=60)

    if response.status_code == 200:
        try:
            data = response.json()
            if isinstance(data, dict):
                # OpenAI æ ¼å¼: {"choices": [{"message": {"content": "..."}}]}
                if "choices" in data:
                    return data["choices"][0]["message"]["content"]
                # ç®€åŒ–æ ¼å¼: {"content": "..."}
                elif "content" in data:
                    return data["content"]
                elif "reasoning_content" in data:
                    return data["reasoning_content"]
                else:
                    return json_module.dumps(data, ensure_ascii=False)
            elif isinstance(data, str):
                return data
            else:
                return json_module.dumps(data, ensure_ascii=False)
        except:
            # çº¯æ–‡æœ¬å“åº”
            return response.text.strip()
    else:
        raise Exception(f"Pollinations API è¯·æ±‚å¤±è´¥: {response.status_code} - {response.text}")


def _call_gitee_ai(messages: list) -> str:
    """
    è°ƒç”¨ Gitee AI API (fallback)ï¼Œä½¿ç”¨ stream æ¨¡å¼é¿å…è¶…æ—¶

    Args:
        messages: OpenAI æ ¼å¼çš„æ¶ˆæ¯åˆ—è¡¨

    Returns:
        AI å“åº”å†…å®¹
    """
    import json

    if not GITEE_AI_API_KEY:
        raise Exception("GITEE_AI_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®")

    headers = {
        'Content-Type': 'application/json',
        'Authorization': f'Bearer {GITEE_AI_API_KEY}',
        'Accept': 'text/event-stream',
    }

    payload = {
        "model": GITEE_AI_MODEL,
        "messages": messages,
        "temperature": 0.7,
        "stream": True,
    }

    response = requests.post(
        GITEE_AI_API_URL,
        json=payload,
        headers=headers,
        timeout=(10, 300),
        stream=True
    )

    if response.status_code != 200:
        raise Exception(f"Gitee AI è¯·æ±‚å¤±è´¥: {response.status_code} - {response.text}")

    full_content = []

    for line in response.iter_lines():
        if not line:
            continue

        line = line.decode('utf-8')

        if line.startswith('data: '):
            data_str = line[6:]

            if data_str == '[DONE]':
                break

            try:
                data = json.loads(data_str)
                if "choices" in data and len(data["choices"]) > 0:
                    delta = data["choices"][0].get("delta", {})
                    content = delta.get("content", "")
                    if content:
                        full_content.append(content)
            except json.JSONDecodeError:
                continue

    if not full_content:
        raise Exception("Gitee AI è¿”å›ç©ºå“åº”")

    return "".join(full_content)


def _call_nvidia_ai(messages: list) -> str:
    """
    è°ƒç”¨ NVIDIA API (fallback 2)ï¼Œä½¿ç”¨ stream æ¨¡å¼

    Args:
        messages: OpenAI æ ¼å¼çš„æ¶ˆæ¯åˆ—è¡¨

    Returns:
        AI å“åº”å†…å®¹
    """
    import json

    if not NVIDIA_API_KEY:
        raise Exception("NVIDIA_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®")

    headers = {
        'Content-Type': 'application/json',
        'Authorization': f'Bearer {NVIDIA_API_KEY}',
        'Accept': 'text/event-stream',
    }

    payload = {
        "model": NVIDIA_MODEL,
        "messages": messages,
        "temperature": 0.7,
        "stream": True,
    }

    response = requests.post(
        NVIDIA_API_URL,
        json=payload,
        headers=headers,
        timeout=(10, 300),
        stream=True
    )

    if response.status_code != 200:
        raise Exception(f"NVIDIA API è¯·æ±‚å¤±è´¥: {response.status_code} - {response.text}")

    full_content = []

    for line in response.iter_lines():
        if not line:
            continue

        line = line.decode('utf-8')

        if line.startswith('data: '):
            data_str = line[6:]

            if data_str == '[DONE]':
                break

            try:
                data = json.loads(data_str)
                if "choices" in data and len(data["choices"]) > 0:
                    delta = data["choices"][0].get("delta", {})
                    content = delta.get("content", "")
                    if content:
                        full_content.append(content)
            except json.JSONDecodeError:
                continue

    if not full_content:
        raise Exception("NVIDIA API è¿”å›ç©ºå“åº”")

    return "".join(full_content)


# ========== æç¤ºè¯æ£€æµ‹ ==========

# æ£€æµ‹ "prompt åœ¨è¯„è®ºä¸­" çš„æŒ‡ç¤ºç¬¦æ¨¡å¼
PROMPT_IN_REPLY_PATTERNS = [
    r'prompt\s*[ğŸ‘‡â¬‡ï¸â†“ğŸ”½]',
    r'[ğŸ‘‡â¬‡ï¸â†“ğŸ”½]\s*prompt',
    r'prompt\s+below',
    r'prompt\s+in\s+(the\s+)?(comment|reply|replies|thread)',
    r'check\s+(the\s+)?(comment|reply|replies)',
    r'see\s+(the\s+)?(comment|reply|replies)',
    r'(comment|reply|replies)\s+for\s+prompt',
    r'full\s+prompt\s+[ğŸ‘‡â¬‡ï¸â†“ğŸ”½]',
    r'æç¤ºè¯\s*[ğŸ‘‡â¬‡ï¸â†“ğŸ”½]',
    r'[ğŸ‘‡â¬‡ï¸â†“ğŸ”½]\s*æç¤ºè¯',
]


def detect_prompt_in_reply(text: str) -> bool:
    """
    æ£€æµ‹æ–‡æœ¬æ˜¯å¦è¡¨æ˜ prompt åœ¨è¯„è®º/å›å¤ä¸­

    Args:
        text: æ–‡æœ¬å†…å®¹

    Returns:
        True å¦‚æœæ£€æµ‹åˆ° prompt å¯èƒ½åœ¨è¯„è®ºä¸­
    """
    if not text:
        return False

    text_lower = text.lower()

    for pattern in PROMPT_IN_REPLY_PATTERNS:
        if re.search(pattern, text_lower, re.IGNORECASE):
            return True

    return False


# ========== æç¤ºè¯æå– ==========

def extract_prompt_regex(text: str) -> str:
    """
    ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ä»æ–‡æœ¬ä¸­æå– prompt
    ç”¨äºå¿«é€Ÿæå–æ ¼å¼è§„èŒƒçš„ promptï¼Œé¿å… AI è°ƒç”¨

    Args:
        text: æ–‡æœ¬å†…å®¹

    Returns:
        æå–çš„ prompt æˆ– None
    """
    if not text:
        return None

    # å¸¸è§çš„ prompt å¼•å¯¼æ¨¡å¼
    patterns = [
        # ğŸ‘‰Prompt: ... æˆ– Prompt: ...
        r'(?:ğŸ‘‰\s*)?[Pp]rompt[:\s]+(.+)',
        # "prompt" åé¢è·Ÿç€æ¢è¡Œå’Œå†…å®¹
        r'[Pp]rompt\s*\n+(.+)',
    ]

    for pattern in patterns:
        match = re.search(pattern, text, re.DOTALL | re.IGNORECASE)
        if match:
            prompt = match.group(1).strip()
            # æ¸…ç†å¼€å¤´çš„å¼•å·ã€æ‹¬å·ç­‰
            prompt = re.sub(r'^[\"\'\[\(]+', '', prompt)
            # å¦‚æœ prompt è¶³å¤Ÿé•¿ï¼Œè®¤ä¸ºæ˜¯æœ‰æ•ˆçš„
            if len(prompt) > 50:
                return prompt

    return None


def extract_prompt(text: str, model: str = DEFAULT_MODEL, use_ai: bool = True) -> dict:
    """
    ä»æ–‡æœ¬ä¸­æå–æç¤ºè¯ï¼ˆä¸»å‡½æ•°ï¼‰

    å…ˆå°è¯•æ­£åˆ™è¡¨è¾¾å¼ï¼Œå¤±è´¥åä½¿ç”¨ AI

    Args:
        text: æ–‡æœ¬å†…å®¹
        model: AI æ¨¡å‹åç§°
        use_ai: æ˜¯å¦ä½¿ç”¨ AIï¼ˆæ­£åˆ™å¤±è´¥æ—¶ï¼‰

    Returns:
        dict: {
            "prompt": æå–çš„ prompt æˆ– None,
            "location": "post" | "reply" | None,
            "method": "regex" | "ai" | None
        }
    """
    result = {
        "prompt": None,
        "location": None,
        "method": None
    }

    if not text:
        return result

    # é¦–å…ˆæ£€æµ‹æ˜¯å¦æ˜¯ "prompt åœ¨è¯„è®ºä¸­" çš„æƒ…å†µ
    if detect_prompt_in_reply(text):
        result["prompt"] = "Prompt in reply"
        result["location"] = "reply"
        result["method"] = "pattern"
        return result

    # å°è¯•æ­£åˆ™è¡¨è¾¾å¼æå–
    regex_result = extract_prompt_regex(text)
    if regex_result:
        result["prompt"] = regex_result
        result["location"] = "post"
        result["method"] = "regex"
        return result

    # ä½¿ç”¨ AI æå–
    if use_ai:
        try:
            ai_result = _extract_prompt_with_ai(text, model)
            if ai_result and ai_result not in ["No prompt found", "Prompt in reply", "Advertisement"]:
                result["prompt"] = ai_result
                result["location"] = "post"
                result["method"] = "ai"
            elif ai_result == "Prompt in reply":
                result["prompt"] = "Prompt in reply"
                result["location"] = "reply"
                result["method"] = "ai"
            elif ai_result == "Advertisement":
                result["prompt"] = "Advertisement"
                result["location"] = None
                result["method"] = "ai"
        except Exception as e:
            print(f"âš ï¸ AI æå–å¤±è´¥: {e}")

    return result


def _extract_prompt_with_ai(text: str, model: str = DEFAULT_MODEL) -> str:
    """
    ä½¿ç”¨ AI API ä»æ–‡æœ¬ä¸­æå–æç¤ºè¯

    Args:
        text: æ–‡æœ¬å†…å®¹
        model: ä½¿ç”¨çš„æ¨¡å‹

    Returns:
        æå–å‡ºçš„æç¤ºè¯ï¼Œæˆ–ç‰¹æ®Šå€¼:
        - "Prompt in reply": prompt åœ¨è¯„è®º/å›å¤ä¸­
        - "No prompt found": æœªæ‰¾åˆ° prompt
        - "Advertisement": å†…å®¹æ˜¯å¹¿å‘Š/æ¨å¹¿
    """
    messages = [
        {
            "role": "system",
            "content": """You are a helpful assistant that extracts AI image generation prompts from text.

IMPORTANT RULES:
1. FIRST, check if this is an advertisement or promotional content. Signs of ads include:
   - Product promotions, sales, discounts, deals
   - Service promotions (courses, tools, subscriptions)
   - Affiliate links, referral codes, promo codes
   - "Buy now", "Limited time", "Sign up", "Join", "Subscribe"
   - App/software promotions without actual prompts
   - Giveaways that require following/retweeting
   - Self-promotion of services or products
   If it's an advertisement, return 'Advertisement'.

2. Extract only the actual prompt itself, without any additional explanation or formatting.
3. If the text contains indicators like "PromptğŸ‘‡", "prompt below", "check comment", "prompt in reply" etc., it means the actual prompt is in a reply/comment, not in the main post. In this case, return 'Prompt in reply'.
4. If the text only contains a title or description of what the image shows (like "Nano Banana prompt" or "Any person to Trash Pop Collage") but NOT the actual detailed prompt, return 'No prompt found'.
5. A real prompt usually contains detailed descriptions, style parameters (like --ar, --v), or specific technical terms.
6. If no actual prompt is found, return 'No prompt found'."""
        },
        {
            "role": "user",
            "content": f"Extract the AI image generation prompt from this text and return only the prompt itself:\n\n{text}"
        }
    ]

    return call_ai(messages, model)


def extract_prompt_simple(text: str, model: str = DEFAULT_MODEL) -> str:
    """
    ç®€å•çš„ AI æå–ï¼ˆä¸æ£€æµ‹ "Prompt in reply"ï¼‰
    ç”¨äºä»å·²çŸ¥åŒ…å« prompt çš„æ–‡æœ¬ä¸­æå–

    Args:
        text: æ–‡æœ¬å†…å®¹
        model: ä½¿ç”¨çš„æ¨¡å‹

    Returns:
        æå–å‡ºçš„æç¤ºè¯æˆ– None
    """
    # å…ˆå°è¯•æ­£åˆ™
    regex_result = extract_prompt_regex(text)
    if regex_result:
        return regex_result

    # AI æå–
    messages = [
        {
            "role": "system",
            "content": "You are a helpful assistant that extracts AI image generation prompts from text. Extract only the prompt itself, without any additional explanation or formatting. If no prompt is found, return 'No prompt found'."
        },
        {
            "role": "user",
            "content": f"Extract the AI image generation prompt from this text and return only the prompt itself:\n\n{text}"
        }
    ]

    try:
        result = call_ai(messages, model)
        if result and result != "No prompt found":
            return result
    except Exception as e:
        print(f"âš ï¸ AI æå–å¤±è´¥: {e}")

    return None


# ========== æç¤ºè¯åˆ†ç±» ==========

# é¢„å®šä¹‰çš„åˆ†ç±»åˆ—è¡¨
PROMPT_CATEGORIES = [
    "äººåƒ/è‚–åƒ (Portrait)",
    "é£æ™¯/è‡ªç„¶ (Landscape/Nature)",
    "åŠ¨ç‰© (Animals)",
    "å»ºç­‘/åŸå¸‚ (Architecture/Urban)",
    "æŠ½è±¡è‰ºæœ¯ (Abstract Art)",
    "ç§‘å¹»/æœªæ¥ (Sci-Fi/Futuristic)",
    "å¥‡å¹»/é­”æ³• (Fantasy/Magic)",
    "åŠ¨æ¼«/å¡é€š (Anime/Cartoon)",
    "å†™å®æ‘„å½± (Realistic Photography)",
    "æ’ç”»/ç»˜ç”» (Illustration/Painting)",
    "æ—¶å°š/æœè£… (Fashion/Clothing)",
    "é£Ÿç‰©/ç¾é£Ÿ (Food)",
    "äº§å“/å•†ä¸š (Product/Commercial)",
    "ææ€–/é»‘æš— (Horror/Dark)",
    "å¯çˆ±/èŒç³» (Cute/Kawaii)",
    "å¤å¤/æ€€æ—§ (Vintage/Retro)",
    "æç®€ä¸»ä¹‰ (Minimalist)",
    "è¶…ç°å® (Surreal)",
    "å…¶ä»– (Other)",
]


def classify_prompt(prompt: str, model: str = DEFAULT_MODEL) -> dict:
    """
    ä½¿ç”¨ AI å¯¹æç¤ºè¯è¿›è¡Œåˆ†ç±»

    Args:
        prompt: æç¤ºè¯å†…å®¹
        model: ä½¿ç”¨çš„æ¨¡å‹

    Returns:
        åˆ†ç±»ç»“æœå­—å…¸: {
            "title": "æ ‡é¢˜",
            "category": "åˆ†ç±»",
            "sub_categories": ["æ¬¡åˆ†ç±»"],
            "style": "é£æ ¼",
            "confidence": "high/medium/low",
            "reason": "åŸå› "
        }
    """
    import json

    categories_str = "\n".join([f"- {cat}" for cat in PROMPT_CATEGORIES])

    messages = [
        {
            "role": "system",
            "content": f"""You are an AI image prompt classifier. Analyze the given prompt and classify it into one of the following categories:

{categories_str}

Respond in JSON format with exactly these fields:
- "title": a concise, descriptive title for this prompt in English (3-8 words, like a short headline)
- "category": the main category (choose from the list above, use the English part only, e.g., "Portrait", "Landscape/Nature")
- "sub_categories": array of 1-3 secondary categories in English (e.g., ["Fashion/Clothing", "Realistic Photography"])
- "style": detected art style (e.g., "photorealistic", "anime", "oil painting", "3D render", etc.)
- "confidence": "high", "medium", or "low"
- "reason": brief explanation in English (1 sentence)

Example response:
{{"title": "Fashion Actress Bird's Eye View", "category": "Portrait", "sub_categories": ["Fashion/Clothing"], "style": "photorealistic", "confidence": "high", "reason": "The prompt describes a Japanese actress in a black coat from above"}}"""
        },
        {
            "role": "user",
            "content": f"Classify this AI image generation prompt:\n\n{prompt}"
        }
    ]

    try:
        response_text = call_ai(messages, model)

        result = None

        # æ¸…ç†å“åº”æ–‡æœ¬
        cleaned_text = response_text.strip()

        # ç§»é™¤å¯èƒ½çš„ markdown ä»£ç å—æ ‡è®°
        if cleaned_text.startswith("```json"):
            cleaned_text = cleaned_text[7:]
        elif cleaned_text.startswith("```"):
            cleaned_text = cleaned_text[3:]
        if cleaned_text.endswith("```"):
            cleaned_text = cleaned_text[:-3]
        cleaned_text = cleaned_text.strip()

        # å°è¯•ç›´æ¥è§£æ
        try:
            result = json.loads(cleaned_text)
        except json.JSONDecodeError:
            # å°è¯•ä»å“åº”ä¸­æå– JSON
            json_match = re.search(r'\{.*\}', cleaned_text, re.DOTALL)
            if json_match:
                try:
                    result = json.loads(json_match.group())
                except:
                    pass

        if not result:
            print(f"âš ï¸ JSON è§£æå¤±è´¥ï¼ŒåŸå§‹å“åº”: {response_text[:200]}")
            return {
                "title": "Untitled Prompt",
                "category": "Other",
                "sub_categories": [],
                "style": "unknown",
                "confidence": "low",
                "reason": "Failed to parse classification result"
            }

        # æ ‡å‡†åŒ–ç»“æœ
        normalized = {
            "title": result.get("title", "Untitled Prompt"),
            "category": result.get("category", "Other"),
            "sub_categories": result.get("sub_categories", []),
            "style": result.get("style", "unknown"),
            "confidence": result.get("confidence", "medium"),
            "reason": result.get("reason", ""),
        }

        # ç¡®ä¿ title æ˜¯å­—ç¬¦ä¸²
        if not isinstance(normalized["title"], str) or not normalized["title"].strip():
            normalized["title"] = "Untitled Prompt"

        # ç¡®ä¿ sub_categories æ˜¯åˆ—è¡¨
        if not isinstance(normalized["sub_categories"], list):
            normalized["sub_categories"] = []

        # æ¸…ç† sub_categories
        cleaned_tags = []
        for tag in normalized["sub_categories"]:
            if isinstance(tag, str) and tag.strip():
                cleaned_tags.append(tag.strip())
        normalized["sub_categories"] = cleaned_tags

        # æ·»åŠ  style åˆ° tags ä¸­
        if normalized["style"] and normalized["style"] != "unknown":
            if normalized["style"] not in normalized["sub_categories"]:
                normalized["sub_categories"].append(normalized["style"])

        return normalized

    except requests.exceptions.Timeout:
        raise Exception("API è¯·æ±‚è¶…æ—¶")
    except Exception as e:
        raise Exception(f"åˆ†ç±»å¤±è´¥: {e}")


# ========== ä¾¿æ·å‡½æ•° ==========

def extract_and_validate_prompt(raw_text: str, model: str = DEFAULT_MODEL) -> dict:
    """
    ç»Ÿä¸€çš„ prompt æå–å’ŒéªŒè¯å‡½æ•°ï¼ˆä¾›å¯¼å…¥è„šæœ¬ä½¿ç”¨ï¼‰

    å¯¹åŸå§‹æ–‡æœ¬è¿›è¡Œ AI æå–ï¼Œå¹¶éªŒè¯ç»“æœæ˜¯å¦æœ‰æ•ˆã€‚

    Args:
        raw_text: åŸå§‹æ–‡æœ¬å†…å®¹
        model: AI æ¨¡å‹åç§°

    Returns:
        dict: {
            "success": bool,           # æ˜¯å¦æˆåŠŸæå–åˆ°æœ‰æ•ˆ prompt
            "prompt": str or None,     # æå–çš„ promptï¼ˆæˆåŠŸæ—¶ï¼‰
            "method": str,             # æå–æ–¹æ³•: "regex" | "ai"
            "error": str or None       # é”™è¯¯ä¿¡æ¯ï¼ˆå¤±è´¥æ—¶ï¼‰
        }
    """
    if not raw_text or not raw_text.strip():
        return {
            "success": False,
            "prompt": None,
            "method": None,
            "error": "Empty input text"
        }

    try:
        result = extract_prompt(raw_text, model=model, use_ai=True)
        prompt = result.get("prompt")
        method = result.get("method", "unknown")

        # æ£€æŸ¥ç‰¹æ®Šè¿”å›å€¼
        if not prompt:
            return {
                "success": False,
                "prompt": None,
                "method": method,
                "error": "AI extraction returned empty"
            }

        if prompt == "Advertisement":
            return {
                "success": False,
                "prompt": None,
                "method": method,
                "error": "Advertisement content"
            }

        if prompt == "Prompt in reply":
            return {
                "success": False,
                "prompt": None,
                "method": method,
                "error": "Prompt in reply"
            }

        if prompt == "No prompt found":
            return {
                "success": False,
                "prompt": None,
                "method": method,
                "error": "No prompt found by AI"
            }

        # æˆåŠŸ
        return {
            "success": True,
            "prompt": prompt,
            "method": method,
            "error": None
        }

    except Exception as e:
        return {
            "success": False,
            "prompt": None,
            "method": None,
            "error": f"AI extraction failed: {e}"
        }


def process_text(text: str, model: str = DEFAULT_MODEL, classify: bool = True) -> dict:
    """
    ä¸€ç«™å¼å¤„ç†ï¼šæå–æç¤ºè¯å¹¶åˆ†ç±»

    Args:
        text: æ–‡æœ¬å†…å®¹
        model: AI æ¨¡å‹
        classify: æ˜¯å¦åˆ†ç±»

    Returns:
        dict: {
            "prompt": æå–çš„ prompt,
            "location": "post" | "reply",
            "method": "regex" | "ai",
            "classification": åˆ†ç±»ç»“æœ (å¦‚æœ classify=True)
        }
    """
    result = extract_prompt(text, model)

    if classify and result["prompt"] and result["prompt"] not in ["Prompt in reply", "No prompt found"]:
        try:
            result["classification"] = classify_prompt(result["prompt"], model)
        except Exception as e:
            print(f"âš ï¸ åˆ†ç±»å¤±è´¥: {e}")
            result["classification"] = None
    else:
        result["classification"] = None

    return result
